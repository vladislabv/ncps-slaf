{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea9306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbcf8fa-bb8a-411f-a75a-67ea6ccbfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# utils packages\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ncps.torch import LTC\n",
    "from ncps.wirings import AutoNCP\n",
    "\n",
    "\n",
    "import project.utils as utils\n",
    "from project.model import SequenceLearner\n",
    "from run import read_data\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d445849",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ff8d52-8e2e-40a3-b11f-cd7af657a985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T17:16:56.714589Z",
     "start_time": "2024-09-03T17:16:56.710630Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction = {}\n",
    "mapes = {}\n",
    "# make sure .ipy_checkpoints is not included // provide path to the ready checkpoints or checkpoint files\n",
    "model_paths = [\"pl_checkpoints/\" + file for file in os.listdir(\"pl_checkpoints/\") if not file.startswith(\".ipy\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3f70fa-dab6-43b2-9834-74298ee43a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for evaluation\n",
    "data_raw = read_data(Config.PATH)\n",
    "data_raw = utils.prepare_data(data_raw, station=Config.STATION, features=Config.FEATURES_LIST)\n",
    "min_value, max_value = data_raw.value.min(), data_raw.value.max()\n",
    "test_data = data_raw.copy()\n",
    "test_data = utils.make_features(test_data, features=Config.FEATURES_LIST)\n",
    "\n",
    "x_features, y_features = utils.generate_test_data(\n",
    "    test_data,\n",
    "    Config.FILTER_DT_TILL,\n",
    "    features=Config.FEATURES_LIST,\n",
    "    push_y_by = 365,\n",
    "    unit = 'd',\n",
    ")\n",
    "\n",
    "x_features_std = (x_features - min_value) / (max_value - min_value)\n",
    "y_features_std = (y_features - min_value) / (max_value - min_value)\n",
    "\n",
    "x_features = x_features_std.copy()\n",
    "y_features = y_features_std.copy()\n",
    "\n",
    "out_features = y_features.shape[-1]\n",
    "in_features = x_features.shape[-1]\n",
    "\n",
    "ds = data_utils.TensorDataset(\n",
    "    torch.Tensor(x_features),\n",
    "    torch.Tensor(y_features)\n",
    ")\n",
    "\n",
    "dataloader = data_utils.DataLoader(\n",
    "    ds,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    shuffle=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c21043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use that if you ignoring model by saving hyperparameters,\n",
    "# the model should match the model used for creating a checkpoint\n",
    "wiring = AutoNCP(8, out_features)  # 16 units, 1 motor neuron\n",
    "\n",
    "ltc_model = LTC(\n",
    "    in_features,\n",
    "    wiring,\n",
    "    batch_first=True,\n",
    "    use_swish_activation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d449d-1294-4185-ba45-f76e4395ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "MAPE = MeanAbsolutePercentageError()\n",
    "\n",
    "for path in model_paths:\n",
    "    trainer = SequenceLearner.load_from_checkpoint(path, model=ltc_model)\n",
    "    model = trainer.model\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    try:\n",
    "        prediction[path] = model(\n",
    "            torch.Tensor(x_features).view(1, -1, in_features).to(device))[0].detach().numpy()\n",
    "\n",
    "        pred_values = prediction[path].squeeze(0)\n",
    "        pred_values_scaled = pred_values * (max_value - min_value) + min_value\n",
    "        tens_pred = torch.from_numpy(pred_values_scaled).squeeze(1)\n",
    "\n",
    "        y_values_scaled = y_features * (max_value - min_value) + min_value\n",
    "        tens_y = torch.from_numpy(y_values_scaled).squeeze(1)\n",
    "\n",
    "        score = MAPE(tens_pred, tens_y)\n",
    "        mapes[path] = score.item()\n",
    "    except Exception as e:\n",
    "        prediction[path] = f\"error for this model: {e}\"\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(sorted(mapes.items(), key=lambda item: item[1] if not np.isnan(item[1]) else 9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ee2ce-38ed-48bb-b86d-5457b0d9c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in prediction.items():\n",
    "    if \"error\" in value:\n",
    "        continue \n",
    "\n",
    "    value = prediction[key].squeeze(0).squeeze(1)\n",
    "    error_torch = round(mapes[key], 5)\n",
    "\n",
    "    name = \" \".join(key.split(\"/\")[1].replace(\".ckpt\", \"\").replace(\"model-\", \"\").split(\"=\")) + \"\\n\" + \"TORCH_MAPE: \" + str(error_torch)\n",
    "\n",
    "    sns.set_theme()\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(y_features.squeeze(1), label=\"Target output\")\n",
    "    plt.plot(value, label=\"NCP output\")\n",
    "\n",
    "    plt.title(f\"After Training\\n{name}\")\n",
    "    plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faef592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "d = pd.read_csv(\"log/default/version_65/metrics.csv\")\n",
    "\n",
    "sns.set_theme()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(d[\"epoch\"], d[\"train_loss\"], label=\"Training Loss\")\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.title(f\"Training Loss of a LNN by Epoch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
